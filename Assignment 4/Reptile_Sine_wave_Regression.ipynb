{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.11"
    },
    "colab": {
      "name": "Reptile_Sine wave Regression.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ashaaher/Emerging-Technologies/blob/master/Assignment%204/Reptile_Sine_wave_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ln16q4LIRi7G"
      },
      "source": [
        "# Sine wave Regression Using Reptile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjvq6-rWR8cJ"
      },
      "source": [
        "Importing necessary libraries "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uenh4RM0kuye",
        "outputId": "663c196a-179f-423e-bc1a-ee736ba1076a"
      },
      "source": [
        "!pip install tensorflow==1.12.0\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bd/68/ec26b2cb070a5760707ec8d9491a24e5be72f4885f265bb04abf70c0f9f1/tensorflow-1.12.0-cp27-cp27mu-manylinux1_x86_64.whl (83.1MB)\n",
            "\u001b[K     |████████████████████████████████| 83.1MB 77kB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Requirement already satisfied: mock>=2.0.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (2.0.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.0.8)\n",
            "Requirement already satisfied: enum34>=1.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.1.6)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (3.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (0.2.2)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (0.35.1)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (0.7.1)\n",
            "Requirement already satisfied: backports.weakref>=1.0rc1 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.0.post1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.15.0)\n",
            "Collecting tensorboard<1.13.0,>=1.12.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/51/ae/9840c4837c6f54034ac942b5344396e8c3d74686a9bd29beafdf633cc221/tensorboard-1.12.2-py2-none-any.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 23.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.16.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python2.7/dist-packages (from tensorflow==1.12.0) (0.8.0)\n",
            "Requirement already satisfied: futures>=2.2.0 in /usr/local/lib/python2.7/dist-packages (from grpcio>=1.8.6->tensorflow==1.12.0) (3.2.0)\n",
            "Requirement already satisfied: funcsigs>=1; python_version < \"3.3\" in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.12.0) (1.0.2)\n",
            "Requirement already satisfied: pbr>=0.11 in /usr/local/lib/python2.7/dist-packages (from mock>=2.0.0->tensorflow==1.12.0) (5.4.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python2.7/dist-packages (from keras-applications>=1.0.6->tensorflow==1.12.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python2.7/dist-packages (from protobuf>=3.6.1->tensorflow==1.12.0) (44.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (0.15.5)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python2.7/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow==1.12.0) (3.1.1)\n",
            "Installing collected packages: tensorboard, tensorflow\n",
            "  Found existing installation: tensorboard 2.1.0\n",
            "    Uninstalling tensorboard-2.1.0:\n",
            "      Successfully uninstalled tensorboard-2.1.0\n",
            "  Found existing installation: tensorflow 2.1.0\n",
            "    Uninstalling tensorflow-2.1.0:\n",
            "      Successfully uninstalled tensorflow-2.1.0\n",
            "Successfully installed tensorboard-1.12.2 tensorflow-1.12.0\n",
            "1.12.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruO50iJORi7G"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DxxH_Y_Ri7G"
      },
      "source": [
        "Generating Data Points"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JKlmYoE-Ri7G"
      },
      "source": [
        "Defining a function called sample_points for generating (x,y) pairs. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSKyZaOYRi7G"
      },
      "source": [
        "def sample_points(k):\n",
        "    \n",
        "    num_points = 100\n",
        "    \n",
        "    #amplitude\n",
        "    amplitude = np.random.uniform(low=0.1, high=5.0)\n",
        "    \n",
        "    #phase\n",
        "    phase = np.random.uniform(low=0, high=np.pi)\n",
        "\n",
        "    x = np.linspace(-5, 5, num_points)\n",
        "\n",
        "    #y = a*sin(x+b)\n",
        "    y = amplitude * np.sin(x + phase)\n",
        "    \n",
        "    #sample k data points\n",
        "    sample = np.random.choice(np.arange(num_points), size=k)\n",
        "    \n",
        "    return (x[sample], y[sample])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9X1f2lgRi7H",
        "outputId": "0e8db2e3-c209-4d30-95b9-e6f91355b952"
      },
      "source": [
        "x, y = sample_points(5)\n",
        "print x\n",
        "print y"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[-0.25252525  2.07070707 -1.16161616  1.46464646  3.58585859]\n",
            "[-0.37038692  2.72439658 -2.89830817  3.40299759 -1.8884191 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Td6sciQLRi7H"
      },
      "source": [
        "Two Layered Neural Network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpUiPUyzRi7H"
      },
      "source": [
        "# resetting the tensorflow graph.\n",
        "#tf.reset_default_graph()\n",
        "tf.reset_default_graph()\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JijXl3gVRi7H"
      },
      "source": [
        "Initializing network parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCeqaApjRi7H"
      },
      "source": [
        "num_hidden = 64\n",
        "num_classes = 1\n",
        "num_feature = 1"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cF_FiYg5Ri7H"
      },
      "source": [
        "Defining the placeholders for input and output."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VF7_6v2iRi7H"
      },
      "source": [
        "#tf.compat.v1.disable_eager_execution()\n",
        "X = tf.placeholder(tf.float32, shape=[None, num_feature])\n",
        "Y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vq5xMIpRi7I"
      },
      "source": [
        "Randomly initialize model parameters, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXwVOZIURi7I"
      },
      "source": [
        "w1 = tf.Variable(tf.random_uniform([num_feature, num_hidden]))\n",
        "b1 = tf.Variable(tf.random_uniform([num_hidden]))\n",
        "\n",
        "w2 = tf.Variable(tf.random_uniform([num_hidden, num_classes]))\n",
        "b2 = tf.Variable(tf.random_uniform([num_classes]))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1Q99YYsRi7I"
      },
      "source": [
        "feedforward operation to predict the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ze1fTi4xRi7I"
      },
      "source": [
        "#layer 1\n",
        "z1 = tf.matmul(X, w1) + b1\n",
        "a1 = tf.nn.tanh(z1)\n",
        "\n",
        "#output layer\n",
        "z2 = tf.matmul(a1, w2) + b2\n",
        "Yhat = tf.nn.tanh(z2)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JtaQlHGYRi7I"
      },
      "source": [
        "Using loss function-Mean Squared "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-sR0wexRi7I"
      },
      "source": [
        "loss_function = tf.reduce_mean(tf.square(Yhat - Y))"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyqRQSRgRi7I"
      },
      "source": [
        "Using Adam Optimizer to optimise the loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG9hYipxRi7I"
      },
      "source": [
        "optimizer = tf.train.AdamOptimizer(1e-2).minimize(loss_function)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5vMldfLSRi7I"
      },
      "source": [
        "Initializing tensorflow variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S1WPPX-oRi7I"
      },
      "source": [
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYpxvoisRi7I"
      },
      "source": [
        "# Reptile\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kmU_33dyRi7I"
      },
      "source": [
        "#number of epochs i.e training iterations\n",
        "num_epochs = 100\n",
        "\n",
        "\n",
        "#number of samples i.e number of shots\n",
        "num_samples = 50  \n",
        "\n",
        "#number of tasks\n",
        "num_tasks = 2\n",
        "\n",
        "#number of times we want to perform optimization\n",
        "num_iterations = 10\n",
        "\n",
        "\n",
        "#mini btach size\n",
        "mini_batch = 10  "
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "7tyeTZ9YRi7I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36d2cef9-edc3-4ff5-a5a1-124f9f367664"
      },
      "source": [
        "#start the tensorflow session\n",
        "with tf.Session() as sess:\n",
        "    \n",
        "    sess.run(init)\n",
        "    \n",
        "    for e in range(num_epochs):\n",
        "        \n",
        "        #for each task in batch of tasks\n",
        "        for task in range(num_tasks):\n",
        "\n",
        "            #get the initial parameters of the model\n",
        "            old_w1, old_b1, old_w2, old_b2 = sess.run([w1, b1, w2, b2,])\n",
        "\n",
        "            #sample x and y\n",
        "            x_sample, y_sample = sample_points(num_samples)\n",
        "\n",
        "\n",
        "            #for some k number of iterations perform optimization on the task\n",
        "            for k in range(num_iterations):\n",
        "\n",
        "                #get the minibatch x and y\n",
        "                for i in range(0, num_samples, mini_batch):\n",
        "\n",
        "                    #sample mini batch of examples \n",
        "                    x_minibatch = x_sample[i:i+mini_batch]\n",
        "                    y_minibatch = y_sample[i:i+mini_batch]\n",
        "\n",
        "\n",
        "                    train = sess.run(optimizer, feed_dict={X: x_minibatch.reshape(mini_batch,1), \n",
        "                                                           Y: y_minibatch.reshape(mini_batch,1)})\n",
        "\n",
        "            #get the updated model parameters after several iterations of optimization\n",
        "            new_w1, new_b1, new_w2, new_b2 = sess.run([w1, b1, w2, b2])\n",
        "\n",
        "            #Now we perform meta update\n",
        "\n",
        "            #i.e theta = theta + epsilon * (theta_star - theta)\n",
        "\n",
        "            epsilon = 0.1\n",
        "\n",
        "            updated_w1 = old_w1 + epsilon * (new_w1 - old_w1) \n",
        "            updated_b1 = old_b1 + epsilon * (new_b1 - old_b1) \n",
        "\n",
        "            updated_w2 = old_w2 + epsilon * (new_w2 - old_w2) \n",
        "            updated_b2 = old_b2 + epsilon * (new_b2 - old_b2) \n",
        "\n",
        "\n",
        "            #update the model parameter with new parameters\n",
        "            w1.load(updated_w1, sess)\n",
        "            b1.load(updated_b1, sess)\n",
        "\n",
        "            w2.load(updated_w2, sess)\n",
        "            b2.load(updated_b2, sess)\n",
        "\n",
        "        if e%10 == 0:\n",
        "            loss = sess.run(loss_function, feed_dict={X: x_sample.reshape(num_samples,1), Y: y_sample.reshape(num_samples,1)})\n",
        "\n",
        "            print \"Epoch {}: Loss {}\\n\".format(e,loss)             \n",
        "            print 'Updated Model Parameter Theta\\n'\n",
        "            print 'Sampling Next Batch of Tasks \\n'\n",
        "            print '---------------------------------\\n'"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0: Loss 10.4267673492\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 10: Loss 5.72791194916\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 20: Loss 3.79788208008\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 30: Loss 7.13282489777\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 40: Loss 4.74478340149\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 50: Loss 1.23034238815\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 60: Loss 3.21274113655\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 70: Loss 1.01734972\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 80: Loss 0.671186983585\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n",
            "Epoch 90: Loss 6.43803119659\n",
            "\n",
            "Updated Model Parameter Theta\n",
            "\n",
            "Sampling Next Batch of Tasks \n",
            "\n",
            "---------------------------------\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVoou-w6TIfh"
      },
      "source": [
        "Reference : https://github.com/sudharsan13296/Hands-On-Meta-Learning-With-Python/blob/master/07.%20Meta-SGD%20and%20Reptile%20Algorithms/7.7%20Sine%20wave%20Regression%20Using%20Reptile.ipynb"
      ]
    }
  ]
}